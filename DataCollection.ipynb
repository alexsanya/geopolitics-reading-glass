{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2035d7e-b2b4-4432-9266-644be7394bda",
   "metadata": {},
   "source": [
    "# Download comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1684cfc-751e-4d30-8839-83876b8c695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "from urllib.parse import urlencode\n",
    "from typing import Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d12fe5e-d8b7-4b93-af5f-c3a5cb4e9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeCommentsDownloader:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the downloader with API key.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.scrapecreators.com/v1/youtube/video/comments\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'x-api-key': self.api_key,\n",
    "            'User-Agent': 'YouTube-Comments-Downloader/1.0'\n",
    "        })\n",
    "    \n",
    "    def make_request(self, video_url: str, order: str = \"newest\", continuation_token: Optional[str] = None) -> Dict:\n",
    "        \"\"\"Make a request to the API with optional continuation token.\"\"\"\n",
    "        params = {\n",
    "            'url': video_url,\n",
    "            'order': order\n",
    "        }\n",
    "        \n",
    "        if continuation_token:\n",
    "            params['continuationToken'] = continuation_token\n",
    "        \n",
    "        try:\n",
    "            print(self.base_url)\n",
    "            print(params)\n",
    "            response = self.session.get(self.base_url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return {}\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON response: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def download_all_comments(self, video_url: str, order: str = \"newest\", output_file: str = \"output.json\", delay: float = 1.0) -> None:\n",
    "        \"\"\"\n",
    "        Download all comments for a video and save to JSON file.\n",
    "        \n",
    "        Args:\n",
    "            video_url: YouTube video URL\n",
    "            order: Comment order (\"newest\", \"top\", etc.)\n",
    "            output_file: Output JSON file path\n",
    "            delay: Delay between requests in seconds\n",
    "        \"\"\"\n",
    "        print(f\"Starting download for video: {video_url}\")\n",
    "        print(f\"Order: {order}\")\n",
    "        print(f\"Output file: {output_file}\")\n",
    "        \n",
    "        all_chunks = {}\n",
    "        chunk_number = 1\n",
    "        continuation_token = None\n",
    "        total_comments = 0\n",
    "        \n",
    "        while True:\n",
    "            print(f\"\\nFetching chunk {chunk_number}...\")\n",
    "            \n",
    "            # Make request\n",
    "            chunk_data = self.make_request(video_url, order, continuation_token)\n",
    "            \n",
    "            if not chunk_data:\n",
    "                print(\"Failed to fetch data or received empty response\")\n",
    "                break\n",
    "            \n",
    "            # Save chunk data\n",
    "            chunk_key = f\"chunk{chunk_number}\"\n",
    "            all_chunks[chunk_key] = chunk_data\n",
    "            \n",
    "            # Count comments in this chunk\n",
    "            comments_in_chunk = len(chunk_data.get('comments', []))\n",
    "            total_comments += comments_in_chunk\n",
    "            \n",
    "            print(f\"Chunk {chunk_number}: {comments_in_chunk} comments\")\n",
    "            print(f\"Total comments so far: {total_comments}\")\n",
    "            \n",
    "            # Check for continuation token\n",
    "            continuation_token = chunk_data.get('continuationToken')\n",
    "            \n",
    "            if not continuation_token:\n",
    "                print(\"No more pages available\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Continuation token found: {continuation_token[:50]}...\")\n",
    "            \n",
    "            # Save progress periodically\n",
    "            if chunk_number % 5 == 0:\n",
    "                self._save_chunks(all_chunks, output_file)\n",
    "                print(f\"Progress saved to {output_file}\")\n",
    "            \n",
    "            chunk_number += 1\n",
    "            \n",
    "            # Add delay to be respectful to the API\n",
    "            if delay > 0:\n",
    "                time.sleep(delay)\n",
    "        \n",
    "        # Save final results\n",
    "        self._save_chunks(all_chunks, output_file)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Download completed!\")\n",
    "        print(f\"Total chunks: {len(all_chunks)}\")\n",
    "        print(f\"Total comments: {total_comments}\")\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    def _save_chunks(self, chunks_data: Dict, output_file: str) -> None:\n",
    "        \"\"\"Save chunks data to JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(chunks_data, f, indent=2, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to file: {e}\")\n",
    "    \n",
    "    def get_video_stats(self, output_file: str = \"output.json\") -> None:\n",
    "        \"\"\"Print statistics about downloaded comments.\"\"\"\n",
    "        try:\n",
    "            with open(output_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            total_chunks = len(data)\n",
    "            total_comments = 0\n",
    "            creators_comments = 0\n",
    "            verified_comments = 0\n",
    "            \n",
    "            for chunk_key, chunk_data in data.items():\n",
    "                comments = chunk_data.get('comments', [])\n",
    "                total_comments += len(comments)\n",
    "                \n",
    "                for comment in comments:\n",
    "                    author = comment.get('author', {})\n",
    "                    if author.get('isCreator'):\n",
    "                        creators_comments += 1\n",
    "                    if author.get('isVerified'):\n",
    "                        verified_comments += 1\n",
    "            \n",
    "            print(f\"\\nüìä Download Statistics:\")\n",
    "            print(f\"Total chunks: {total_chunks}\")\n",
    "            print(f\"Total comments: {total_comments}\")\n",
    "            print(f\"Creator comments: {creators_comments}\")\n",
    "            print(f\"Verified author comments: {verified_comments}\")\n",
    "            print(f\"Average comments per chunk: {total_comments / total_chunks:.1f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading stats: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e219ce98-7d19-45e6-a741-231f0d5ba2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    dotenv.load_dotenv()\n",
    "    \"\"\"Main function to run the downloader.\"\"\"\n",
    "    # Configuration\n",
    "    API_KEY = os.environ['SCRAPPER_API_KEY']\n",
    "    VIDEO_URL = \"https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63\"  # Replace with target video URL\n",
    "    ORDER = \"newest\"  # or \"top\", \"relevance\", etc.\n",
    "    OUTPUT_FILE = \"output.json\"\n",
    "    REQUEST_DELAY = 1.0  # seconds between requests\n",
    "    \n",
    "    # Initialize downloader\n",
    "    downloader = YouTubeCommentsDownloader(API_KEY)\n",
    "    \n",
    "    try:\n",
    "        # Download all comments\n",
    "        downloader.download_all_comments(\n",
    "            video_url=VIDEO_URL,\n",
    "            order=ORDER,\n",
    "            output_file=OUTPUT_FILE,\n",
    "            delay=REQUEST_DELAY\n",
    "        )\n",
    "        \n",
    "        # Show statistics\n",
    "        downloader.get_video_stats(OUTPUT_FILE)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Download interrupted by user\")\n",
    "        print(\"Partial results may be saved in the output file\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a604d64-bb46-4107-bd24-b34178d46185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for video: https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63\n",
      "Order: newest\n",
      "Output file: output.json\n",
      "\n",
      "Fetching chunk 1...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest'}\n",
      "Chunk 1: 20 comments\n",
      "Total comments so far: 20\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 2...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUhJQmdBRWdVSWlTQVlBQklGQ0owZ0dBRVNCUWlvSUJnQUlnNEtEQWl3eGFIR0JoRElwNkstQVEiESILZVpNMklrLUZIRVUwAXgBKBRCEGNvbW1lbnRzLXNlY3Rpb24%3D'}\n",
      "Chunk 2: 20 comments\n",
      "Total comments so far: 40\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyiwEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 3...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyiwEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUpJQmdBRWdVSWlDQVlBQklGQ0ljZ0dBQVNCUWlvSUJnQUlnMEtDd2ljbmFIR0JoQ285ZGxvIhEiC2VaTTJJay1GSEVVMAF4ASgoQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 3: 20 comments\n",
      "Total comments so far: 60\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyigEKYWdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 4...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyigEKYWdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUpJQmdBRWdVSW5TQVlBUklGQ0lnZ0dBQVNCUWlISUJnQUlnd0tDZ2pfX3FER0JoQ2c5bUEiESILZVpNMklrLUZIRVUwAXgBKDxCEGNvbW1lbnRzLXNlY3Rpb24%3D'}\n",
      "Chunk 4: 20 comments\n",
      "Total comments so far: 80\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 5...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSXFDQVlBQklGQ0owZ0dBRVNCUWlISUJnQUlnNEtEQWp3NnFER0JoQ1FtWWZBQXciESILZVpNMklrLUZIRVUwAXgBKFBCEGNvbW1lbnRzLXNlY3Rpb24%3D'}\n",
      "Chunk 5: 20 comments\n",
      "Total comments so far: 100\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 6...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjQEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0lrZ0dBQVNCUWlISUJnQUlnNEtEQWlxMmFER0JoRFE1Nk9uQXciESILZVpNMklrLUZIRVUwAXgBKGRCEGNvbW1lbnRzLXNlY3Rpb24%3D'}\n",
      "Chunk 6: 20 comments\n",
      "Total comments so far: 120\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyiwEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 7...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyiwEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaW9JQmdBRWdVSW5TQVlBUklGQ0lnZ0dBQVNCUWlISUJnQUlnMEtDd2pYeGFER0JoRFE2YUFWIhEiC2VaTTJJay1GSEVVMAF4ASh4QhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 7: 20 comments\n",
      "Total comments so far: 140\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 8...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaWRJQmdCRWdVSWlTQVlBQklGQ0tnZ0dBQVNCUWlJSUJnQUlnNEtEQWo1cmFER0JoREluLUx2QVEiESILZVpNMklrLUZIRVUwAXgBKIwBQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 8: 20 comments\n",
      "Total comments so far: 160\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 9...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSWh5QVlBQklGQ0owZ0dBRVNCUWlvSUJnQUlnMEtDd2lPbXFER0JoRElqS0FiIhEiC2VaTTJJay1GSEVVMAF4ASigAUIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 9: 20 comments\n",
      "Total comments so far: 180\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 10...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaUlJQmdBRWdVSWlTQVlBQklGQ0tnZ0dBQVNCUWlkSUJnQklnNEtEQWoxNzVfR0JoREFnOVdBQWciESILZVpNMklrLUZIRVUwAXgBKLQBQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 10: 20 comments\n",
      "Total comments so far: 200\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 11...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUpJQmdBRWdVSWh5QVlBQklGQ0lnZ0dBQVNCUWlkSUJnQklnNEtEQWpfeHBfR0JoREF3WUdtQVEiESILZVpNMklrLUZIRVUwAXgBKMgBQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 11: 20 comments\n",
      "Total comments so far: 220\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 12...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlkSUJnQklnNEtEQWpVazVfR0JoQ3d6c3VjQWciESILZVpNMklrLUZIRVUwAXgBKNwBQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 12: 20 comments\n",
      "Total comments so far: 240\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 13...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0lrZ0dBQVNCUWlkSUJnQklnNEtEQWpBNVo3R0JoQ1lzZjNIQWciESILZVpNMklrLUZIRVUwAXgBKPABQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 13: 20 comments\n",
      "Total comments so far: 260\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 14...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaW9JQmdBRWdVSWh5QVlBQklGQ0lnZ0dBQVNCUWlkSUJnQklnMEtDd2lDdHA3R0JoQ0E1WlZQIhEiC2VaTTJJay1GSEVVMAF4ASiEAkIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 14: 20 comments\n",
      "Total comments so far: 280\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 15...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUpJQmdBRWdVSWh5QVlBQklGQ0owZ0dBRVNCUWlJSUJnQUlnNEtEQWlXaUo3R0JoRG9nSV9VQXciESILZVpNMklrLUZIRVUwAXgBKJgCQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 15: 20 comments\n",
      "Total comments so far: 300\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 16...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlkSUJnQklnMEtDd2l3NkozR0JoREl2Y2wzIhEiC2VaTTJJay1GSEVVMAF4ASisAkIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 16: 20 comments\n",
      "Total comments so far: 320\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 17...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0lrZ0dBQVNCUWlISUJnQUlnMEtDd2o4eUozR0JoQ3cyNkFoIhEiC2VaTTJJay1GSEVVMAF4ASjAAkIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 17: 20 comments\n",
      "Total comments so far: 340\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 18...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaWRJQmdCRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlKSUJnQUlnNEtEQWpobFozR0JoQ1kxcjMzQVEiESILZVpNMklrLUZIRVUwAXgBKNQCQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 18: 20 comments\n",
      "Total comments so far: 360\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 19...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUlJQmdBRWdVSXFDQVlBQklGQ0lrZ0dBQVNCUWlISUJnQUlnNEtEQWpyLVp6R0JoQ291ZmlJQXciESILZVpNMklrLUZIRVUwAXgBKOgCQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 19: 20 comments\n",
      "Total comments so far: 380\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 20...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaWRJQmdCRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlKSUJnQUlnMEtDd2ozNDV6R0JoRDRpS3hwIhEiC2VaTTJJay1GSEVVMAF4ASj8AkIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 20: 20 comments\n",
      "Total comments so far: 400\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 21...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0owZ0dBRVNCUWlKSUJnQUlnMEtDd2puenB6R0JoQ0Ffb1p0IhEiC2VaTTJJay1GSEVVMAF4ASiQA0IQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 21: 20 comments\n",
      "Total comments so far: 420\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 22...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUhJQmdBRWdVSXFDQVlBQklGQ0lrZ0dBQVNCUWlkSUJnQklnNEtEQWp1dDV6R0JoQ29qZnVCQWciESILZVpNMklrLUZIRVUwAXgBKKQDQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 22: 20 comments\n",
      "Total comments so far: 440\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 23...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0ljZ0dBQVNCUWlkSUJnQklnMEtDd2pBcHB6R0JoQ0k1cHhEIhEiC2VaTTJJay1GSEVVMAF4ASi4A0IQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 23: 20 comments\n",
      "Total comments so far: 460\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 24...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaUlJQmdBRWdVSWlTQVlBQklGQ0tnZ0dBQVNCUWlkSUJnQklnNEtEQWpTbEp6R0JoQ3d3NERTQWciESILZVpNMklrLUZIRVUwAXgBKMwDQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 24: 20 comments\n",
      "Total comments so far: 480\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 25...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUpJQmdBRWdVSWh5QVlBQklGQ0lnZ0dBQVNCUWlvSUJnQUlnNEtEQWpCaTV6R0JoQ295dDd6QWciESILZVpNMklrLUZIRVUwAXgBKOADQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 25: 20 comments\n",
      "Total comments so far: 500\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 26...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSW5TQVlBUklGQ0ljZ0dBQVNCUWlvSUJnQUlnNEtEQWpKZ3B6R0JoRFEwYVdUQVEiESILZVpNMklrLUZIRVUwAXgBKPQDQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 26: 20 comments\n",
      "Total comments so far: 520\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 27...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaWRJQmdCRWdVSWlDQVlBQklGQ0lrZ0dBQVNCUWlvSUJnQUlnNEtEQWlWLTV2R0JoRG95Y3lEQWciESILZVpNMklrLUZIRVUwAXgBKIgEQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 27: 20 comments\n",
      "Total comments so far: 540\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 28...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUlJQmdBRWdVSWh5QVlBQklGQ0owZ0dBRVNCUWlKSUJnQUlnNEtEQWlkOEp2R0JoRFlfSjZIQVEiESILZVpNMklrLUZIRVUwAXgBKJwEQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 28: 20 comments\n",
      "Total comments so far: 560\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 29...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUlJQmdBRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlKSUJnQUlnNEtEQWllNXB2R0JoQ1FvZDNkQWciESILZVpNMklrLUZIRVUwAXgBKLAEQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 29: 20 comments\n",
      "Total comments so far: 580\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 30...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaUlJQmdBRWdVSW5TQVlBUklGQ0tnZ0dBQVNCUWlKSUJnQUlnNEtEQWoxMnB2R0JoQ3ducnpRQWciESILZVpNMklrLUZIRVUwAXgBKMQEQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 30: 20 comments\n",
      "Total comments so far: 600\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 31...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaUlJQmdBRWdVSWh5QVlBQklGQ0owZ0dBRVNCUWlvSUJnQUlnMEtDd2lqenB2R0JoQ1kwZUJoIhEiC2VaTTJJay1GSEVVMAF4ASjYBEIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 31: 20 comments\n",
      "Total comments so far: 620\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 32...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUlJQmdBRWdVSWlTQVlBQklGQ0ljZ0dBQVNCUWlvSUJnQUlnNEtEQWpYeDV2R0JoQ0FxZGpqQWciESILZVpNMklrLUZIRVUwAXgBKOwEQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 32: 20 comments\n",
      "Total comments so far: 640\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 33...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaWRJQmdCRWdVSWlTQVlBQklGQ0tnZ0dBQVNCUWlISUJnQUlnNEtEQWlrdlp2R0JoQzRyc0hEQWciESILZVpNMklrLUZIRVUwAXgBKIAFQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 33: 20 comments\n",
      "Total comments so far: 660\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 34...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaWRJQmdCRWdVSWlDQVlBQklGQ0lrZ0dBQVNCUWlISUJnQUlnNEtEQWpHczV2R0JoREFfSm5QQVEiESILZVpNMklrLUZIRVUwAXgBKJQFQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 34: 20 comments\n",
      "Total comments so far: 680\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 35...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaW9JQmdBRWdVSW5TQVlBUklGQ0ljZ0dBQVNCUWlKSUJnQUlnMEtDd2lNcnB2R0JoRGc1YThuIhEiC2VaTTJJay1GSEVVMAF4ASioBUIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 35: 20 comments\n",
      "Total comments so far: 700\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 36...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaW9JQmdBRWdVSWlDQVlBQklGQ0owZ0dBRVNCUWlKSUJnQUlnMEtDd2lScEp2R0JoQ1E1NWdSIhEiC2VaTTJJay1GSEVVMAF4ASi8BUIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 36: 20 comments\n",
      "Total comments so far: 720\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 37...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaUlJQmdBRWdVSWh5QVlBQklGQ0tnZ0dBQVNCUWlkSUJnQklnNEtEQWpRbTV2R0JoRG9uNkdXQWciESILZVpNMklrLUZIRVUwAXgBKNAFQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 37: 20 comments\n",
      "Total comments so far: 740\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 38...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUlJQmdBRWdVSWlTQVlBQklGQ0ljZ0dBQVNCUWlkSUJnQklnMEtDd2prbHB2R0JoQ0FxUDFCIhEiC2VaTTJJay1GSEVVMAF4ASjkBUIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 38: 20 comments\n",
      "Total comments so far: 760\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 39...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaUlJQmdBRWdVSXFDQVlBQklGQ0lrZ0dBQVNCUWlkSUJnQklnNEtEQWpHajV2R0JoQ1EydFN3QWciESILZVpNMklrLUZIRVUwAXgBKPgFQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 39: 20 comments\n",
      "Total comments so far: 780\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 40...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaUlJQmdBRWdVSWh5QVlBQklGQ0tnZ0dBQVNCUWlkSUJnQklnNEtEQWlpaVp2R0JoREl4T2pZQWciESILZVpNMklrLUZIRVUwAXgBKIwGQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 40: 20 comments\n",
      "Total comments so far: 800\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 41...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUpJQmdBRWdVSWh5QVlBQklGQ0owZ0dBRVNCUWlvSUJnQUlnNEtEQWpzaEp2R0JoREF3OEhGQWciESILZVpNMklrLUZIRVUwAXgBKKAGQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 41: 20 comments\n",
      "Total comments so far: 820\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 42...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSjBnR0FFU0JRaUpJQmdBRWdVSWlDQVlBQklGQ0ljZ0dBQVNCUWlvSUJnQUlnNEtEQWppZ0p2R0JoRGd2N0NYQWciESILZVpNMklrLUZIRVUwAXgBKLQGQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 42: 20 comments\n",
      "Total comments so far: 840\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 43...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjAEKYmdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaUlJQmdBRWdVSW5TQVlBUklGQ0lrZ0dBQVNCUWlISUJnQUlnMEtDd2pnLVpyR0JoRGdxSTRkIhEiC2VaTTJJay1GSEVVMAF4ASjIBkIQY29tbWVudHMtc2VjdGlvbg%3D%3D'}\n",
      "Chunk 43: 20 comments\n",
      "Total comments so far: 860\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 44...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaW9JQmdBRWdVSW5TQVlBUklGQ0ljZ0dBQVNCUWlKSUJnQUlnNEtEQWo2OUpyR0JoQ0l5bzNUQWciESILZVpNMklrLUZIRVUwAXgBKNwGQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 44: 20 comments\n",
      "Total comments so far: 880\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 45...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaWRJQmdCRWdVSWlDQVlBQklGQ0tnZ0dBQVNCUWlKSUJnQUlnNEtEQWlHOEpyR0JoRFl5YmJWQWciESILZVpNMklrLUZIRVUwAXgBKPAGQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 45: 20 comments\n",
      "Total comments so far: 900\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "Progress saved to output.json\n",
      "\n",
      "Fetching chunk 46...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDS2dnR0FBU0JRaWRJQmdCRWdVSWh5QVlBQklGQ0lnZ0dBQVNCUWlKSUJnQUlnNEtEQWpIN0pyR0JoQ1EyUDNyQVEiESILZVpNMklrLUZIRVUwAXgBKIQHQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 46: 20 comments\n",
      "Total comments so far: 920\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 47...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaWRJQmdCRWdVSXFDQVlBQklGQ0ljZ0dBQVNCUWlKSUJnQUlnNEtEQWpkNTVyR0JoRFk4Y2JxQVEiESILZVpNMklrLUZIRVUwAXgBKJgHQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 47: 20 comments\n",
      "Total comments so far: 940\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 48...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWNnR0FBU0JRaWRJQmdCRWdVSWlDQVlBQklGQ0tnZ0dBQVNCUWlKSUJnQUlnNEtEQWpmNUpyR0JoQ1lfNEtSQXciESILZVpNMklrLUZIRVUwAXgBKKwHQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 48: 20 comments\n",
      "Total comments so far: 960\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 49...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWtnR0FBU0JRaWRJQmdCRWdVSWh5QVlBQklGQ0lnZ0dBQVNCUWlvSUJnQUlnNEtEQWl3MzVyR0JoQzQzTkxVQWciESILZVpNMklrLUZIRVUwAXgBKMAHQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 49: 20 comments\n",
      "Total comments so far: 980\n",
      "Continuation token found: Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3...\n",
      "\n",
      "Fetching chunk 50...\n",
      "https://api.scrapecreators.com/v1/youtube/video/comments\n",
      "{'url': 'https://youtu.be/eZM2Ik-FHEU?si=73Rw2GQxCCzDqg63', 'order': 'newest', 'continuationToken': 'Eg0SC2VaTTJJay1GSEVVGAYyjgEKZGdldF9uZXdlc3RfZmlyc3QtLUNnZ0lnQVFWRjdmUk9CSUZDSWdnR0FBU0JRaUhJQmdBRWdVSWlTQVlBQklGQ0owZ0dBRVNCUWlvSUJnQUlnNEtEQWl2M1pyR0JoQ2duXy1nQXciESILZVpNMklrLUZIRVUwAXgBKNQHQhBjb21tZW50cy1zZWN0aW9u'}\n",
      "Chunk 50: 1 comments\n",
      "Total comments so far: 981\n",
      "No more pages available\n",
      "\n",
      "‚úÖ Download completed!\n",
      "Total chunks: 50\n",
      "Total comments: 981\n",
      "Results saved to: output.json\n",
      "\n",
      "üìä Download Statistics:\n",
      "Total chunks: 50\n",
      "Total comments: 981\n",
      "Creator comments: 2\n",
      "Verified author comments: 0\n",
      "Average comments per chunk: 19.6\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2388ea-c7a8-45f0-ae9a-ad8edbf62f4b",
   "metadata": {},
   "source": [
    "# Add comments to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d7f07c-da7f-4272-9d15-dc987fdb019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c4c13c-1e30-4832-a8a6-81f1e20a8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_comments_data(json_file: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load comments data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to the JSON file containing comment chunks\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing all comment chunks\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"‚úÖ Successfully loaded {len(data)} chunks from {json_file}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: File '{json_file}' not found\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå Error parsing JSON: {e}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading file: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_comments_from_chunks(chunks_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract all comments from all chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks_data: Dictionary containing comment chunks\n",
    "        \n",
    "    Returns:\n",
    "        List of all comments from all chunks\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    \n",
    "    for chunk_key, chunk_data in chunks_data.items():\n",
    "        comments = chunk_data.get('comments', [])\n",
    "        print(f\"Chunk {chunk_key}: {len(comments)} comments\")\n",
    "        all_comments.extend(comments)\n",
    "    \n",
    "    print(f\"üìä Total comments extracted: {len(all_comments)}\")\n",
    "    return all_comments\n",
    "\n",
    "\n",
    "def parse_published_time(published_time_str: str) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Parse published time string to pandas Timestamp.\n",
    "    \n",
    "    Args:\n",
    "        published_time_str: ISO format datetime string\n",
    "        \n",
    "    Returns:\n",
    "        Pandas Timestamp object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(published_time_str)\n",
    "    except:\n",
    "        # If parsing fails, return NaT (Not a Time)\n",
    "        return pd.NaT\n",
    "\n",
    "\n",
    "def create_dataframe(comments: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create pandas DataFrame from comments list.\n",
    "    \n",
    "    Args:\n",
    "        comments: List of comment dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        Pandas DataFrame with columns: content, published_at, likes, replies\n",
    "    \"\"\"\n",
    "    processed_comments = []\n",
    "    \n",
    "    for comment in comments:\n",
    "        # Extract required fields\n",
    "        content = comment.get('content', '')\n",
    "        published_time = comment.get('publishedTime', '')\n",
    "        \n",
    "        # Extract engagement data\n",
    "        engagement = comment.get('engagement', {})\n",
    "        likes = engagement.get('likes', 0)\n",
    "        replies = engagement.get('replies', 0)\n",
    "        \n",
    "        # Parse published time\n",
    "        published_at = parse_published_time(published_time)\n",
    "        \n",
    "        processed_comments.append({\n",
    "            'content': content,\n",
    "            'published_at': published_at,\n",
    "            'likes': likes,\n",
    "            'replies': replies\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(processed_comments)\n",
    "    \n",
    "    # Ensure data types\n",
    "    df['content'] = df['content'].astype(str)\n",
    "    df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "    df['likes'] = pd.to_numeric(df['likes'], errors='coerce').fillna(0).astype(int)\n",
    "    df['replies'] = pd.to_numeric(df['replies'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_dataframe(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print analysis of the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame to analyze\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìà DataFrame Analysis:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nüìä Data Summary:\")\n",
    "    print(f\"Total comments: {len(df)}\")\n",
    "    print(f\"Date range: {df['published_at'].min()} to {df['published_at'].max()}\")\n",
    "    print(f\"Total likes: {df['likes'].sum():,}\")\n",
    "    print(f\"Total replies: {df['replies'].sum():,}\")\n",
    "    print(f\"Average likes per comment: {df['likes'].mean():.2f}\")\n",
    "    print(f\"Average replies per comment: {df['replies'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\nüîç Top Stats:\")\n",
    "    print(f\"Most liked comment: {df['likes'].max()} likes\")\n",
    "    print(f\"Most replied comment: {df['replies'].max()} replies\")\n",
    "    \n",
    "    # Show top 3 most liked comments (first 100 chars)\n",
    "    print(f\"\\nüèÜ Top 3 Most Liked Comments:\")\n",
    "    top_liked = df.nlargest(3, 'likes')\n",
    "    for i, (_, row) in enumerate(top_liked.iterrows(), 1):\n",
    "        content_preview = row['content'][:100] + \"...\" if len(row['content']) > 100 else row['content']\n",
    "        print(f\"{i}. {row['likes']} likes: {content_preview}\")\n",
    "    \n",
    "    # Data quality check\n",
    "    print(f\"\\nüîç Data Quality:\")\n",
    "    print(f\"Missing published_at: {df['published_at'].isna().sum()}\")\n",
    "    print(f\"Empty content: {(df['content'] == '').sum()}\")\n",
    "    print(f\"Zero engagement (no likes/replies): {((df['likes'] == 0) & (df['replies'] == 0)).sum()}\")\n",
    "\n",
    "\n",
    "def save_dataframe(df: pd.DataFrame, output_formats: List[str] = ['csv']) -> None:\n",
    "    \"\"\"\n",
    "    Save DataFrame in various formats.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame to save\n",
    "        output_formats: List of formats to save ('csv', 'excel', 'parquet')\n",
    "    \"\"\"\n",
    "    base_name = \"youtube_comments\"\n",
    "    \n",
    "    for format_type in output_formats:\n",
    "        try:\n",
    "            if format_type == 'csv':\n",
    "                filename = f\"{base_name}.csv\"\n",
    "                df.to_csv(filename, index=False, encoding='utf-8')\n",
    "                print(f\"üíæ Saved as CSV: {filename}\")\n",
    "                \n",
    "            elif format_type == 'excel':\n",
    "                filename = f\"{base_name}.xlsx\"\n",
    "                df.to_excel(filename, index=False, engine='openpyxl')\n",
    "                print(f\"üíæ Saved as Excel: {filename}\")\n",
    "                \n",
    "            elif format_type == 'parquet':\n",
    "                filename = f\"{base_name}.parquet\"\n",
    "                df.to_parquet(filename, index=False)\n",
    "                print(f\"üíæ Saved as Parquet: {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving as {format_type}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "851d67da-a632-48e6-bf1d-7e4d041174bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dataframe():\n",
    "    \"\"\"Main function to convert JSON to DataFrame.\"\"\"\n",
    "    # Configuration\n",
    "    json_file = \"output.json\"\n",
    "    save_formats = ['csv']  # Options: 'csv', 'excel', 'parquet'\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(json_file):\n",
    "        print(f\"‚ùå File '{json_file}' does not exist\")\n",
    "        print(\"Make sure to run the YouTube comments downloader first\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîÑ Converting {json_file} to Pandas DataFrame...\")\n",
    "    \n",
    "    # Load data\n",
    "    chunks_data = load_comments_data(json_file)\n",
    "    if not chunks_data:\n",
    "        return\n",
    "    \n",
    "    # Extract comments\n",
    "    all_comments = extract_comments_from_chunks(chunks_data)\n",
    "    if not all_comments:\n",
    "        print(\"‚ùå No comments found in the data\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    print(\"üîÑ Creating Pandas DataFrame...\")\n",
    "    df = create_dataframe(all_comments)\n",
    "    \n",
    "    # Show DataFrame info\n",
    "    print(f\"‚úÖ DataFrame created successfully!\")\n",
    "    print(f\"\\nDataFrame Head:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nDataFrame Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Analyze data\n",
    "    analyze_dataframe(df)\n",
    "    \n",
    "    # Save DataFrame\n",
    "    if save_formats:\n",
    "        print(f\"\\nüíæ Saving DataFrame in {len(save_formats)} format(s)...\")\n",
    "        save_dataframe(df, save_formats)\n",
    "    \n",
    "    # Return DataFrame for interactive use\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1e3a33-924b-42e1-b212-ca4f4113ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting output.json to Pandas DataFrame...\n",
      "‚úÖ Successfully loaded 50 chunks from output.json\n",
      "Chunk chunk1: 20 comments\n",
      "Chunk chunk2: 20 comments\n",
      "Chunk chunk3: 20 comments\n",
      "Chunk chunk4: 20 comments\n",
      "Chunk chunk5: 20 comments\n",
      "Chunk chunk6: 20 comments\n",
      "Chunk chunk7: 20 comments\n",
      "Chunk chunk8: 20 comments\n",
      "Chunk chunk9: 20 comments\n",
      "Chunk chunk10: 20 comments\n",
      "Chunk chunk11: 20 comments\n",
      "Chunk chunk12: 20 comments\n",
      "Chunk chunk13: 20 comments\n",
      "Chunk chunk14: 20 comments\n",
      "Chunk chunk15: 20 comments\n",
      "Chunk chunk16: 20 comments\n",
      "Chunk chunk17: 20 comments\n",
      "Chunk chunk18: 20 comments\n",
      "Chunk chunk19: 20 comments\n",
      "Chunk chunk20: 20 comments\n",
      "Chunk chunk21: 20 comments\n",
      "Chunk chunk22: 20 comments\n",
      "Chunk chunk23: 20 comments\n",
      "Chunk chunk24: 20 comments\n",
      "Chunk chunk25: 20 comments\n",
      "Chunk chunk26: 20 comments\n",
      "Chunk chunk27: 20 comments\n",
      "Chunk chunk28: 20 comments\n",
      "Chunk chunk29: 20 comments\n",
      "Chunk chunk30: 20 comments\n",
      "Chunk chunk31: 20 comments\n",
      "Chunk chunk32: 20 comments\n",
      "Chunk chunk33: 20 comments\n",
      "Chunk chunk34: 20 comments\n",
      "Chunk chunk35: 20 comments\n",
      "Chunk chunk36: 20 comments\n",
      "Chunk chunk37: 20 comments\n",
      "Chunk chunk38: 20 comments\n",
      "Chunk chunk39: 20 comments\n",
      "Chunk chunk40: 20 comments\n",
      "Chunk chunk41: 20 comments\n",
      "Chunk chunk42: 20 comments\n",
      "Chunk chunk43: 20 comments\n",
      "Chunk chunk44: 20 comments\n",
      "Chunk chunk45: 20 comments\n",
      "Chunk chunk46: 20 comments\n",
      "Chunk chunk47: 20 comments\n",
      "Chunk chunk48: 20 comments\n",
      "Chunk chunk49: 20 comments\n",
      "Chunk chunk50: 1 comments\n",
      "üìä Total comments extracted: 981\n",
      "üîÑ Creating Pandas DataFrame...\n",
      "‚úÖ DataFrame created successfully!\n",
      "\n",
      "DataFrame Head:\n",
      "                                             content  \\\n",
      "0  Stay better informed https://ground.news/caspi...   \n",
      "1                 it's not a conflict its a genocide   \n",
      "2  Lured-in with promises of peace...\\nWas that B...   \n",
      "3  with friends like these who needs enemies and ...   \n",
      "4         Qatar mediates while funding terrorism lol   \n",
      "\n",
      "                      published_at  likes  replies  \n",
      "0 2025-09-14 19:52:09.110000+00:00     50       14  \n",
      "1 2025-09-15 19:52:09.110000+00:00      0        0  \n",
      "2 2025-09-15 19:52:09.110000+00:00      0        0  \n",
      "3 2025-09-15 19:52:09.110000+00:00      0        0  \n",
      "4 2025-09-15 19:52:09.110000+00:00      0        0  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   content       981 non-null    object             \n",
      " 1   published_at  981 non-null    datetime64[ns, UTC]\n",
      " 2   likes         981 non-null    int64              \n",
      " 3   replies       981 non-null    int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(1)\n",
      "memory usage: 30.8+ KB\n",
      "None\n",
      "\n",
      "üìà DataFrame Analysis:\n",
      "Shape: (981, 4)\n",
      "Columns: ['content', 'published_at', 'likes', 'replies']\n",
      "\n",
      "üìä Data Summary:\n",
      "Total comments: 981\n",
      "Date range: 2025-09-14 19:52:09.110000+00:00 to 2025-09-15 19:52:54.767000+00:00\n",
      "Total likes: 12,143\n",
      "Total replies: 1,539\n",
      "Average likes per comment: 12.38\n",
      "Average replies per comment: 1.57\n",
      "\n",
      "üîç Top Stats:\n",
      "Most liked comment: 1600 likes\n",
      "Most replied comment: 159 replies\n",
      "\n",
      "üèÜ Top 3 Most Liked Comments:\n",
      "1. 1600 likes: US security guarantees are now meaningless. We're being pushed backwards into a \"every man for himse...\n",
      "2. 1500 likes: Tried to play both sides got attacked by both Iran and Israel lol\n",
      "3. 1300 likes: Its almost like the israeli government doesnt want peace\n",
      "\n",
      "üîç Data Quality:\n",
      "Missing published_at: 0\n",
      "Empty content: 0\n",
      "Zero engagement (no likes/replies): 594\n",
      "\n",
      "üíæ Saving DataFrame in 1 format(s)...\n",
      "üíæ Saved as CSV: youtube_comments.csv\n"
     ]
    }
   ],
   "source": [
    "df = load_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c3453e0-2d81-427a-9162-57809ebd3402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "625a315e-59d3-4547-b574-9999ee67fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>published_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay better informed https://ground.news/caspi...</td>\n",
       "      <td>2025-09-14 19:52:09.110000+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's not a conflict its a genocide</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lured-in with promises of peace...\\nWas that B...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with friends like these who needs enemies and ...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qatar mediates while funding terrorism lol</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Funny the obvious route for Israel above Syria...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>At war with all neighbors (sans US backed Jord...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@CaspianReport In your video \"How Israel plans...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The \"messenger\" here is the biggest provider o...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It seems that you forgot to mention the multib...</td>\n",
       "      <td>2025-09-15 19:52:09.110000+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Stay better informed https://ground.news/caspi...   \n",
       "1                 it's not a conflict its a genocide   \n",
       "2  Lured-in with promises of peace...\\nWas that B...   \n",
       "3  with friends like these who needs enemies and ...   \n",
       "4         Qatar mediates while funding terrorism lol   \n",
       "5  Funny the obvious route for Israel above Syria...   \n",
       "6  At war with all neighbors (sans US backed Jord...   \n",
       "7  @CaspianReport In your video \"How Israel plans...   \n",
       "8  The \"messenger\" here is the biggest provider o...   \n",
       "9  It seems that you forgot to mention the multib...   \n",
       "\n",
       "                      published_at  likes  replies  \n",
       "0 2025-09-14 19:52:09.110000+00:00     50       14  \n",
       "1 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "2 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "3 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "4 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "5 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "6 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "7 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "8 2025-09-15 19:52:09.110000+00:00      0        0  \n",
       "9 2025-09-15 19:52:09.110000+00:00      0        0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805cd64-21bc-4870-aa00-61621a11bbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
